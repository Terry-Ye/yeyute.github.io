[{"title":"golang 排序练习题学习","date":"2017-03-03T05:38:54.000Z","path":"2017/03/03/golang-排序练习题学习/","text":"练习题目来源于 go 语言编程 一书,程序自己测试完成通过 我们将该函数分为两类：主程序和排序算法函数。每个排序算法都包装成一个静态库，虽然现在看起来似乎有些多此一举，但这只是为了顺便演示包之间的依赖方法注：环境变量需要指定到该根目录执行程序，另外文章只是简单的说明构建流程，主要自己看代码理解 目录结构代码 (https://github.com/yeyute/go.git)123456789101112├─&lt;src&gt; ├─&lt;sorter&gt; ├─sorter.go ├─&lt;algorithms&gt; ├─&lt;qsort&gt; ├─qsort.go ├─qsort_test.go ├─&lt;bubblesort&gt; ├─bubblesort.go ├─bubblesort_test.go ├─&lt;pkg&gt;(程序构建时自动创建) ├─&lt;bin&gt;(程序构建时自动创建) 其中sorter.go是主程序qsort.go用于实现快速排序bubblesort.go用于实现冒泡排序 构建程序12345678910$ go build algorithm/qsort$ go build algorithm/bubblesort$ go test algorithm/qsortok algorithm/qsort0.007s$ go test algorithm/bubblesortok algorithm/bubblesort0.013s$ go install algorithm/qsort$ go install algorithm/bubblesort$ go build sorter$ go install sorter 执行安装这些命令，我们应该能够在src的同一级目录下看到两个目录——bin和pkg,然后在bin目录新建unsorted.dat，执行以下 123456789101112131415$ cd bin$ vim unsorted.dat123306436449012353312742132 :wq 保存退出 再执行123456789101112131415161718$ ./sorter -i unsorted.dat -o sorted.dat -a qsort infile = unsorted.dat outfile = sorted.dat algorithm = qsortThe sorting process costs 3us to complete.$ ./sorter -i unsorted.dat -o sorted.dat -a bubblesort infile = unsorted.dat outfile = sorted.dat algorithm = bubblesortThe sorting process costs 2us to complete.$ cat sorted.dat122347236412313249030645331 结果已经被正确排序并写入到sorted.dat文件中,，至此我们的程序也算是完整了 如果有您有帮助，请给个start","tags":[{"name":"golang","slug":"golang","permalink":"http://yoursite.com/tags/golang/"}]},{"title":"golang 环境搭建笔记","date":"2017-02-25T06:12:46.000Z","path":"2017/02/25/go-安装笔记/","text":"下载下载地址：https://golang.org/dl/ mac 安装版本：1.8.1MAC 系统下你可以使用 .pkg 结尾的安装包直接双击来完成安装，安装目录在 /usr/local/go/ 下。 1234567891011121314// 没有bash_profile 则新建vim ~/.bash_profile# 项目路径export GOPATH=/Users/AT/Dropbox/htdocs/go# go执行的执行位置 默认是export GOBIN=/usr/local/go/binexport PATH=$PATH:$GOBIN:wq# 编译source .bash_profile# 查看 go 环境变量是否成功go env windows 安装下载windodws对应的安装版本（msi结尾的），安装完成配置对应的环境变量即可GOROOT: go的安装路径,官方包路径根据这个设置自动匹配GOPATH: 工作路径(其实不应该用中文翻译解释，直接说GOPATH更合适) 输出第一条语句在环境变量 GOPATH的目录下新建 hello.go。1234567package mainimport &quot;fmt&quot;func main() &#123; fmt.Println(&quot;Hello, World!&quot;)&#125; 个人使用sublime的插件执行 1go run hello.go","tags":[{"name":"笔记","slug":"笔记","permalink":"http://yoursite.com/tags/笔记/"},{"name":"golang","slug":"golang","permalink":"http://yoursite.com/tags/golang/"}]},{"title":"Facade外观设计模式","date":"2017-01-22T07:38:31.000Z","path":"2017/01/22/Facade外观设计模式/","text":"简述用于全部api的统一调用方式，规范化代码，后续维护方便具有独立性 和可移植性在 apiImplement类 做接口接入的扩展，例： apiImplement类中的mango 方法 实例化 MangoApi类，调用方式如下 1234567namespace App\\Admin\\Controllers;use App\\Libraries\\Api;// Api::mango() 实例化了 MangoApi类 requestUrl是MangoApi类的方法$rs = Api::mango($data[&apos;api_info&apos;] , function (MangoApi $MangoApi) use ($data) &#123; $MangoApi-&gt;requestUrl($data[&apos;api_info&apos;], $data[&apos;data&apos;]); &#125;); 扩展规范apiImplement类 添加对应的方法，去实例化需要的对象 以下是各文件的类1234567891011// file Api.php namespace App\\Libraries;use App\\Libraries\\Facade;class Api extends Facade &#123; static public function getFacadeAccessor() &#123; return \\App\\Libraries\\Api\\ApiImplement::class; &#125;&#125; Facade.php 通过__callStatic 方法来实现通用 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556// file Facade.phpnamespace App\\Libraries;use RuntimeException;abstract class Facade &#123; static public $resolvedInstance; static public $app; /** * [getFacadeAccessor 获取访问器] * @return [type] [description] */ static public function getFacadeAccessor() &#123; throw new RuntimeException(&apos;Facade does not implement getFacadeAccessor method.&apos;); &#125; /** * [getInstance 获取实例] * @return [object] [instance] */ static public function getFacadeRoot() &#123; return static::resolveFacadeInstance(static::getFacadeAccessor()); &#125; static function resolveFacadeInstance($name) &#123; if( is_object($name) ) &#123; return $name; &#125; if (isset(static::$resolvedInstance[$name])) &#123; return static::$resolvedInstance[$name]; &#125; return static::$resolvedInstance[$name] = new $name(); &#125; /** * [__callStatic ] * @param [string] $method [调用的方法] * @param [array] $args [参数] * @return [mixed] [mixed] */ static public function __callStatic($method,$args) &#123; $instance = self::getFacadeRoot(); if (! $instance) &#123; throw new RuntimeException(&apos;A facade root has not been set.&apos;); &#125; return $instance-&gt;$method(...$args); &#125;&#125; ApiImplement.php12345678910111213141516171819//file ApiImplement.phpnamespace App\\Libraries\\Api;use Closure;class apiImplement &#123; /** * [mango ] * @param [type] $data [description] * @param Closure $callable [description] * @return [type] [description] */ public function mango($data, Closure $callable) &#123; return new MangoApi($data, $callable); &#125;&#125; MangoApi 继承于基类 BaseApi， 初始化对应的接口信息，根据自己的需求进行优化12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455namespace App\\Libraries\\Api;use Closure;use Encore\\Admin\\Exception\\Handle;class MangoApi extends BaseApi &#123; protected $callable; /** * [__construct 构造函数] * @param [type] $api_info [一个api 信息对象] * @param Closure $callable [description] */ public function __construct($api_info,Closure $callback) &#123; $this-&gt;service_name = $api_info-&gt;service_name; // // 必传的参数，用|分隔 $this-&gt;params = $api_info-&gt;params; $this-&gt;return_construction = json_decode($api_info-&gt;return_construction,true); $this-&gt;time = time(); $this-&gt;callable = $callback; $callback($this); &#125; /** * Render the api contents. * * @return string */ public function render() &#123; try &#123; return $this-&gt;callable; &#125; catch (\\Exception $e) &#123; return with(new Handle($e))-&gt;render(); &#125; &#125; /** * Get the string contents of the view. * * @return string */ public function __toString() &#123; return $this-&gt;render(); &#125;&#125; BaseApi.php，可以做成api 的基类，统一继承，目前不可以通用，待改善123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140// file BaseApi.phpnamespace App\\Libraries\\Api;use Closure;use Encore\\Admin\\Exception\\Handle;use Encore\\Admin\\Form\\Builder;use Curl\\Curl;class BaseApi &#123; // 接口的签名 protected $sign; // 配置信息 protected $config; // 请求的body 值 protected $body; // 请求的头部 protected $header; // 接口的服务名 protected $service_name; // 10 位的时间戳 protected $time; // 必传的参数 默认值 protected $params = &quot;productId&quot;; // 错误码 protected $code_config; // 接口返回的数据结构 默认是这个 protected $return_construction = [ &quot;Code&quot; =&gt;0, &quot;Message&quot; =&gt; &quot;success&quot;, &quot;Result&quot; =&gt;&quot;&#123;data&#125;&quot;, ]; public $return_rs; public function init() &#123; $this-&gt;config = config(&apos;product.api&apos;); $this-&gt;code_config = config(&apos;product.error_code&apos;); &#125; /** * [setHeaders 设置头部] * @param [type] $service_name [服务名] * @param [type] $time [当前时间戳] */ protected function setHeaders() &#123; $header = [ //组装请求体 &quot;uid&quot; =&gt;$this-&gt;config[&apos;uid&apos;], &quot;sid&quot; =&gt;$this-&gt;config[&apos;sid&apos;], &quot;Data-Format&quot; =&gt;&quot;json&quot;, &quot;ServiceName&quot; =&gt;$this-&gt;service_name, &quot;Auth-Timestamp&quot; =&gt;$this-&gt;time, &quot;Auth-Signature&quot; =&gt;$this-&gt;sign, ]; $this-&gt;headers = $header; return $this-&gt;headers; &#125; /** * [setBody 设置body内容] * @param [type] $data [数据内容] */ protected function setBody($data) &#123; $this-&gt;body = $data; return $this-&gt;body; &#125; /** * [requestUrl 请求执行URL] * @param [type] $post_json_data [body 请求的数据] * @return [type] [miax] */ public function requestUrl($api_info ,$post_json_data) &#123; // 初始化配置 $this-&gt;init($api_info); // 检查参数 if($this-&gt;checkParam($post_json_data) === false ) &#123; return $this-&gt;code_config[&apos;PARAM_ERROR&apos;]; &#125; // 设置签名 $this-&gt;setSign($post_json_data); // 设置请求头部 $this-&gt;setHeaders(); // 设置请求body $this-&gt;setBody($post_json_data); $curl = new Curl(); $curl-&gt;setHeaders($this-&gt;headers); $rs = $curl-&gt;post($this-&gt;config[&apos;url&apos;],$this-&gt;body); if ($curl-&gt;error) &#123; $data = [ &apos;code&apos; =&gt; $curl-&gt;errorCode, &apos;msg&apos; =&gt; &apos;Error: &apos; . $curl-&gt;errorCode . &apos;: &apos; . $curl-&gt;errorMessage . &quot;\\n&quot;, ]; return $data; &#125; $this-&gt;return_rs = $this-&gt;code_config[&apos;SUCCESS&apos;]; $this-&gt;return_rs[&apos;data&apos;] = $this-&gt;getReturnData($this-&gt;return_construction, json_decode($rs, true)); return $this-&gt;return_rs; &#125; /** * [getReturnData 递归寻找数据那一层] * @param [type] $return_construction[后台填写的数据结构] * @param string $rs_data [接口返回的数据 ] * @param string $get_info [查询的内容] * @return [type] [] */ protected function getReturnData($return_construction, $rs_data, $get_info = &apos;&#123;data&#125;&apos;) &#123; foreach($return_construction as $key=&gt;$val) &#123; if(is_array($val)) &#123; return $this-&gt;getReturnData($val,$rs_data[$key]); &#125;else &#123; if($val === $get_info) &#123; return $rs_data[$key]; &#125; &#125; &#125; return &apos;&apos;; &#125; /** * Get the string contents of the view. * * @return string */ public function __toString() &#123; return $this-&gt;return_rs; &#125;&#125;","tags":[{"name":"php","slug":"php","permalink":"http://yoursite.com/tags/php/"},{"name":"设计模式","slug":"设计模式","permalink":"http://yoursite.com/tags/设计模式/"}]},{"title":"laravel后台框架laravel-admin select框的使用","date":"2016-12-15T04:01:59.000Z","path":"2016/12/15/laravel后台框架laravel-admin-select框的使用/","text":"select 二级联动不能正常获取数据原因使用二级联动时调用的api时，api返回的代码如以下, 12345678910//控制器文件controller.php$this-&gt;form-&gt;select(&apos;sort&apos;, &apos;app&apos;) -&gt;options($sort_type) -&gt;load(&apos;position_id&apos;, &apos;/admin/api_general/get_position&apos;);//api文件 $data = [ &#123;&quot;id&quot;=&gt;&quot;111&quot;,&quot;text&quot;=&gt;&quot;index&quot;&#125;, ];return json_encode($data); 头部信息的格式为 Content-type:text/html; 即使在api文件补上header 12345header(&quot;Content-type: application/json&quot;);$data = [ &#123;&quot;id&quot;=&gt;&quot;111&quot;,&quot;text&quot;=&gt;&quot;index&quot;&#125;, ];return json_encode($data); 结果还是返回Content-type:text/html; 类型 最后使用laravel封装方法解决问题 12345$data = [ &#123;&quot;id&quot;=&gt;&quot;111&quot;,&quot;text&quot;=&gt;&quot;index&quot;&#125;, ];// json 方法会自动将 Content-Type 头设置为 application/json，并使用 PHP 函数 json_encode 方法将给定数组转化为 JSON：return response()-&gt;json($data);","tags":[{"name":"php","slug":"php","permalink":"http://yoursite.com/tags/php/"},{"name":"笔记","slug":"笔记","permalink":"http://yoursite.com/tags/笔记/"}]},{"title":"windows与linux安装node.js","date":"2016-12-01T08:03:11.000Z","path":"2016/12/01/windows与linux安装node-js/","text":"window 安装 安装githttp://blog.csdn.net/shuyou612/article/details/53183683官网安装过于慢的话可以考虑在 http://download.csdn.net/download/u010180815/9726804 下载 下载并安装 Node.js 。使用其 LTS（长期支持）版本。 https://nodejs.org/en/download/windows 8以后的版本安装 msi 文件会 报 the installer has encountered…….. 2503 参考 http://jingyan.baidu.com/article/59a015e34f4870f79488652e.html 现在开始安装相关环境1234// -g 代表全用户安装npm install express -gnpm install jade -g npm install mysql -g linux centOS 安装下载需要的版本 https://nodejs.org/en/download/参考 http://www.cnblogs.com/8765h/p/4777746.html 创建一个工程创建一个工程 123express ship // 如运行cmd 时没有使用管理员身份运行，会报以下错误 // Error: EPERM:operation not permitted,mkdir &apos;C:\\Program Files\\nodejs\\ship&apos; at Error(native) 如终端报错提示 express不是内部或外部命令具体参数 http://jingyan.baidu.com/article/922554468a3466851648f419.html 复制node_modules到ship下面进行测试 新建一个test.js 文件 1234567var http = require(&quot;http&quot;); http.createServer(function(request, response) &#123; response.writeHead(200, &#123;&quot;Content-Type&quot;: &quot;text/plain&quot;&#125;); response.write(&quot;Hello World&quot;); response.end(); &#125;).listen(8888); console.log(&quot;nodejs start listen 8888 port!&quot;); 终端 cd 到C:\\Program Files\\nodejs\\ship 执行 1node test.js 浏览器访问 http://127.0.0.1:8888/ 即可","tags":[{"name":"笔记","slug":"笔记","permalink":"http://yoursite.com/tags/笔记/"},{"name":"nodejs","slug":"nodejs","permalink":"http://yoursite.com/tags/nodejs/"}]},{"title":"使用dockerfile 部署php环境","date":"2016-11-03T06:32:44.000Z","path":"2016/11/03/使用dockerfile-部署php环境/","text":"docker 简介docker 可以运行于任何安装现在linux 内核 的x64主机上，推荐内核版本3.8及以上 为什么使用docker 加速本地的开发和构建流程，容器可以在开发环境构建，然后轻松地提交到测试环境，并最终进入生产环境 能够在让独立的服务或应用程序在不同的环境中得到相同的运行结果 创建隔离的环境来进行测试 高性能、超大规划的宿主机部署 各系统环境安装dockerwindows 7 安装 https://segmentfault.com/n/1330000008349110 mac 使用docker toolbox https://github.com/widuu/chinese_docker/blob/master/installation/mac.md 参考使用该文章 linux 1234567sudo yum updatesudo yum install docker#安装程序将docker程序安装到/usr/bin⺫⽬目录下，配置⽂文件安装在/etc/sysconfig/docker。安装好docker之后，可以 将docker加⼊入到启动服务组中 sudo systemctl enable docker.service#手动启动docker服务器，使⽤用命令 sudo systemctl start docker.service 目录结构 github地址 https://github.com/yeyute/docker-lnmpr 123456789101112131415161718docker_lnmpr├── mysql│ └── Dockerfile └── mysqld.cnf├── nginx│ ├── Dockerfile│ ├── nginx.conf│ └── vhost│ └── www.texixi.com.conf├── php│ ├── Dockerfile│ ├── composer.phar│ ├── php-fpm.conf│ ├── php.ini│ ├── redis-3.0.0.tgz└── redis └── Dockerfile └── redis.conf 建立镜像与容器1234567891011121314# builddocker build -t centos/nginx:v1.11.5 -v /www:/www -v /data:/data ./nginxdocker build -t centos/mysql:v5.7 -v /data/mysql:/var/lib/mysql -v /data/logs/mysql:/var/log/mysql ./mysqldocker build -t centos/php:v7.0.12 -v /www:/www -v /data:/data ./phpdocker build -t centos/redis:v3.2.6 -v /data:/data ./redis#备注：这里选取了172.172.0.0网段，也可以指定其他任意空闲的网段docker network create --subnet=172.171.0.0/16 docker-at# rundocker run --name mysql57 --net docker-at --ip 172.171.0.9 -d -p 3306:3306 -v /data/mysql:/var/lib/mysql -v /data/logs/mysql:/var/log/mysql -v /data/run/mysqlmysqld:/var/run/mysqld -e MYSQL_ROOT_PASSWORD=123456 -it centos/mysql:v5.7docker run --name redis326 --net docker-at --ip 172.171.0.10 -d -p 6379:6379 -v /data:/data -it centos/redis:v3.2.6docker run --name php7 --net docker-at --ip 172.171.0.8 -d -p 9000:9000 -v /www:/www -v /data:/data --link mysql57:mysql57 --link redis326:redis326 -it centos/php:v7.0.12 docker run --name nginx11 --net docker-at --ip 172.171.0.7 -p 80:80 -d -v /www:/www -v /data:/data --link php7:php7 -it centos/nginx:v1.11.5 常用命令 docker start 容器名（容器ID也可以） docker stop 容器名（容器ID也可以） docker run 命令加 -d 参数，docker 会将容器放到后台运行 docker ps 正在运行的容器 docker logs –tail 10 -tf 容器名 查看容器的日志文件,加-t是加上时间戳，f是跟踪某个容器的最新日志而不必读整个日志文件 docker top 容器名 查看容器内部运行的进程 docker exec -d 容器名 touch /etc/new_config_file 通过后台命令创建一个空文件 docker run –restart=always –name 容器名 -d ubuntu /bin/sh -c “while true;do echo hello world; sleep 1; done” 无论退出代码是什么，docker都会自动重启容器，可以设置 –restart=on-failure:5 自动重启的次数 docker inspect 容器名 对容器进行详细的检查，可以加 –format=’{(.State.Running)}’ 来获取指定的信息 docker rm 容器ID 删除容器，注，运行中的容器无法删除 docker rm docker ps -a -q 这样可以删除所有的容器 docker images 列出镜像 docker pull 镜像名:标签 拉镜像 docker search 查找docker Hub 上公共的可用镜像 docker build -t=’AT/web_server:v1’ 命令后面可以直接加上github仓库的要目录下存在的Dockerfile文件。 命令是编写Dockerfile 之后使用的。-t选项为新镜像设置了仓库和名称:标签 docker login 登陆到Docker Hub，个人认证信息将会保存到$HOME/.dockercfg, docker commit -m=”comment “ –author=”AT” 容器ID 镜像的用户名/仓库名:标签 不推荐这种方法，推荐dockerfile docker history 镜像ID 深入探求镜像是如何构建出来的 docker port 镜像ID 端口 查看映射情况的容器的ID和容器的端口号，假设查询80端口对应的映射的端口 run 运行一个容器， -p 8080:80 将容器内的80端口映射到docker宿主机的某一特定端口，将容器的80端口绑定到宿主机的8080端口，另 127.0.0.1:80:80 是将容器的80端口绑定到宿主机这个IP的80端口上，-P 是将容器内的80端口对本地的宿主机公开 http://docs.docker.com/reference/builder/ 查看更多的命令 docker push 镜像名 将镜像推送到 Docker Hub docker rmi 镜像名 删除镜像 docker attach 容器ID 进入容器 删除所有容器和镜像的命令 12docker rm `docker ps -a |awk &apos;&#123;print $1&#125;&apos; | grep [0-9a-z]` 删除停止的容器docker rmi $(docker images | awk &apos;/^&lt;none&gt;/ &#123; print $3 &#125;&apos;) 进入容器的命令 1234[root@iZ287mq5dooZ nginx]# docker inspect --format &quot;&#123;&#123; .State.Pid &#125;&#125;&quot; 54a454b827e5(容器ID)20426[root@iZ287mq5dooZ nginx]# nsenter --target 20426 --mount --uts --ipc --net --pid[root@bcb14764a7a3 /]# dockerfile 语法 MAINTAINER 标识镜像的作者和联系方式 EXPOSE 可以指定多个EXPOSE向外部公开多个端口，可以帮助多个容器链接 FROM 指令指定一个已经存在的镜像 #号代表注释 RUN 运行命令,会在shell 里使用命令包装器 /bin/sh -c 来执行。如果是在一个不支持shell 的平台上运行或者不希望在shell 中运行，也可以 使用exec 格式 的RUN指令 ENV REFRESHED_AT 环境变量 这个环境亦是用来表明镜像模板最后的更新时间 VOLUME 容器添加卷。一个卷是可以 存在于一个或多个容器内的特定的目录，对卷的修改是立刻生效的，对卷的修改不会对更新镜像产品影响，例:VOLUME[“/opt/project”,”/data”] ADD 将构建环境 下的文件 和目录复制到镜像 中。例 ADD nginx.conf /conf/nginx.conf 也可以是取url 的地址文件，如果是压缩包，ADD命令会自动解压、 USER 指定镜像用那个USER 去运行 COPY 是复制本地文件，而不会去做文件提取（解压包不会自动解压） 例：COPY conf.d/ /etc/apache2/ 将本地conf.d目录中的文件复制到/etc/apache2/目录中 问题点整理 docker 服务没启动启动并设置为开机自动启动docker服务 1234567[root@iZ287mq5dooZ docker-php]# docker infoCannot connect to the Docker daemon. Is the docker daemon running on this host?[root@iZ287mq5dooZ docker-php]# ps aux | grep dockerroot 7902 0.0 0.0 112648 956 pts/0 S+ 13:54 0:00 grep --color=auto docker[root@iZ287mq5dooZ docker-php]# service docker startRedirecting to /bin/systemctl start docker.service[root@iZ287mq5dooZ redis]# systemctl start docker 注意挂载目录的权限问题，不然容器成功启动几秒后立刻关闭例：以下/data/run/mysql 目录没权限的情况下就会出现刚才那种情况 1docker run --name mysql57 -d -p 3306:3306 -v /data/mysql:/var/lib/mysql -v /data/logs/mysql:/var/log/mysql -v /data/run/mysql:/var/run/mysqld -e MYSQL_ROOT_PASSWORD=123456 -it centos/mysql:v5.7 需要注意php.ini 中的目录对应 mysql 的配置的目录需要挂载才能获取文件内容，不然php连接mysql失败 12345678# php.inimysql.default_socket = /data/run/mysql/mysqld.sockmysqli.default_socket = /data/run/mysql/mysqld.sockpdo_mysql.default_socket = /data/run/mysql/mysqld.sock# mysqld.cnfpid-file = /var/run/mysqld/mysqld.pidsocket = /var/run/mysqld/mysqld.sock 宿主机 无法访问docker的容器（nginx） https://segmentfault.com/q/1010000008893871，个人提问与回答都在里面 使用php连接不上redis 123# 错误的$redis = new Redis;$rs = $redis-&gt;connect(&apos;127.0.0.1&apos;, 6379); php连接不上，查看错误日志 1PHP Fatal error: Uncaught RedisException: Redis server went away in /www/index.php:7 考虑到docker 之间的通信应该不可以用127.0.0.1 应该使用容器里面的ip，所以查看redis 容器的ip 1234567[root@iZ287mq5dooZ php]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES5fb4b1904f1c centos/nginx:v1.11.5 &quot;/usr/local/nginx/sbi&quot; About an hour ago Up About an hour 0.0.0.0:80-&gt;80/tcp, 443/tcp nginx112bf7ad9f44f9 centos/php:v7.0.12 &quot;/usr/local/php/sbin/&quot; About an hour ago Up About an hour 0.0.0.0:9000-&gt;9000/tcp php74b84858ea4e4 centos/redis:v3.2.6 &quot;/bin/sh -c &apos;\\&quot;/usr/lo&quot; 18 hours ago Up About an hour 0.0.0.0:6379-&gt;6379/tcp redis326158c67aa178c centos/mysql:v5.7 &quot;docker-entrypoint.sh&quot; 6 days ago Up About an hour 0.0.0.0:3306-&gt;3306/tcp mysql57[root@iZ287mq5dooZ php]# docker inspect 4b84858ea4e4 结果是为 192.168.0.4，测试连接，成功 12$redis = new Redis;$rs = $redis-&gt;connect(&apos;192.168.0.4&apos;, 6379); 问题是重启容器ip为动态的，解决该问题 第一步：创建自定义网络 123#备注：这里选取了172.172.0.0网段，也可以指定其他任意空闲的网段docker network create --subnet=172.171.0.0/16 docker-atdocker run --name redis326 --net docker-at --ip 172.171.0.10 -d -p 6379:6379 -v /data:/data -it centos/redis:v3.2.6 连接redis 就可以配置对应的ip地址了，连接成功 12$redis = new Redis;$rs = $redis-&gt;connect(&apos;172.171.0.10&apos;, 6379); 使用docker-compose 报错 12// 使用pip 安装docker-composepip install -U docker-compose 假设没安装pip，会报以下错误，windows 请参数 http://www.cnblogs.com/RSsky/articles/5525999.html 1bash: pip: command not found linux 请执行 1yum install python-pip","tags":[{"name":"笔记","slug":"笔记","permalink":"http://yoursite.com/tags/笔记/"},{"name":"docker","slug":"docker","permalink":"http://yoursite.com/tags/docker/"}]},{"title":"mysql 主从配置原理","date":"2016-05-15T16:18:32.000Z","path":"2016/05/16/mysql-主从配置原理/","text":"复制概述 主服务器将更新写入二进制日志文件，并维护文件的一个索引以跟踪日志循环，这些日志可以记录发送到从服务器的更新。当一个从服务器连接主服务器时，从服务器在日志中读取的最后一次成功更新的位置 复制类型 基于语句的复制： 在主服务器上执行的SQL语句，在从服务器上执行同样的语句。MySQL默认采用基于语句的复制，效率比较高。一旦发现没法精确复制时，会自动选着基于行的复制。 基于行的复制：把改变的内容复制过去，而不是把命令在从服务器上执行一遍. 从mysql5.0开始支持 混合类型的复制: 默认采用基于语句的复制，一旦发现基于语句的无法精确的复制时，就会采用基于行的复制。 复制解决的问题（ MySQL复制技术有以下一些特点 ） 数据分布 (Data distribution) 负载平衡(load balancing) 备份(Backups) 高可用性和容错行 High availability and failover 复制如何工作 master将改变记录到二进制日志(binary log)中（这些记录叫做二进制日志事件，binary log events）； slave将master的binary log events拷贝到它的中继日志(relay log)； slave重做中继日志中的事件，将改变反映它自己的数据。 描述了复制的过程该过程的第一部分就是master记录二进制日志。在每个事务更新数据完成之前，master在二日志记录这些改变。MySQL将事务串行的写入二进制日志，即使事务中的语句都是交叉执行的。在事件写入二进制日志完成后，master通知存储引擎提交事务。下一步就是slave将master的binary log拷贝到它自己的中继日志。首先，slave开始一个工作线程——I/O线程。I/O线程在master上打开一个普通的连接，然后开始binlog dump process。Binlog dump process从master的二进制日志中读取事件，如果已经跟上master，它会睡眠并等待master产生新的事件。I/O线程将这些事件写入中继日志。SQL slave thread（SQL从线程）处理该过程的最后一步。SQL线程从中继日志读取事件，并重放其中的事件而更新slave的数据，使其与master中的数据一致。只要该线程与I/O线程保持一致，中继日志通常会位于OS的缓存中，所以中继日志的开销很小。此外，在master中也有一个工作线程：和其它MySQL的连接一样，slave在master中打开一个连接也会使得master开始一个线程。复制过程有一个很重要的限制——复制在slave上是串行化的，也就是说master上的并行更新操作不能在slave上并行操作。","tags":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/tags/mysql/"},{"name":"笔记","slug":"笔记","permalink":"http://yoursite.com/tags/笔记/"}]},{"title":"适配器设计模式","date":"2016-05-01T15:44:52.000Z","path":"2016/05/01/适配器模式/","text":"适配器的适用场景 代码的复用性强。 我们一直在使用适配器，如果 只有USB连接头，无法将手机插到标准的插座上面充电 ，这时需要的一个适配器，一端接USB连接头，另一端接插座 活动专题，例抽奖，固定的规则是充值有抽奖机会，但是突然来了一个需求说充值还要分享才能有抽奖机会，这时可以运用上这个设计模式 题目一（来自于php 设计模式 书） - 假设一个企业网站同时销售软件服务和软件产品，目前所有的交易都在美国进行，后续业务决定向欧洲发展要增加货币换算（增加适配器）题目二是自已设计于活动专题业务上，只是将逻辑摘取出来，代码不可直接运行 优点 灵活性扩展性都很好 将目标类和适配者类解耦 适配器所涉及的角色包括下面几种：目标（Target）：定义一个客户端使用的特定接口。客户端（Client）：使用目标接口，与和目标接口一致的对象合作。被适配者（Adaptee）：一个现存需要适配的接口。适配器（Adapter）：负责将Adaptee的接口转换为Target的接口。适配器是一个具体的类，这是该模式的核心。适配器分为类适配器和对象适配器两种，下面将详细讲述。 案例一来自 php 设计模式 一书的适配器设计模式案例**123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990/** * EuroCalc.php * 美元 - 能累加购买的服务和产品的价格 来自于php 设计模式 */class DollarCalc &#123; private $dollar; private $product; private $service; public $rate = 1; public function requestCalc($productNow,$serviceNow) &#123; $this-&gt;product = $productNow; $this-&gt;service = $serviceNow; $this-&gt;dollar = $this-&gt;product + $this-&gt;service; return $this-&gt;requestCount(); &#125; private function requestCount() &#123; $this-&gt;dollar *= $this-&gt;rate; return $this-&gt;dollar; &#125;&#125;/** * EuroCalc.php * 欧元 - 能累加购买的服务和产品的价格 */class EuroCalc &#123; private $euro; private $product; private $service; public $rate = 1; public function requestCalc($productNow,$serviceNow) &#123; $this-&gt;product = $productNow; $this-&gt;service = $serviceNow; $this-&gt;euro = $this-&gt;product + $this-&gt;service; return $this-&gt;requestCount(); &#125; private function requestCount() &#123; $this-&gt;euro *= $this-&gt;rate; return $this-&gt;euro; &#125;&#125;/** * 接口 ITarget.php */interface ITarget &#123; function requester();&#125;/** * 例：找一个合适的适配器来适合欧洲的插座一样，以下就是创建这个适配器 * EuroAdapter 实现了一个接口又扩展了一个类 */class EuroAdapter extends EuroCalc implements ITarget &#123; public function __construct() &#123; $this-&gt;requester(); &#125; public function requester() &#123; $this-&gt;rate = 0.8111; return $this-&gt;rate; &#125;&#125;/** * 用户 */class Client &#123; private $euroRequest; private $dollarRequest; public function __construct() &#123; $this-&gt;euroRequest = new EuroAdapter(); $this-&gt;dollarRequest = new DollarCalc(); $euros = &quot;&amp;#8364;&quot;; echo &quot;Euros:$euros&quot;.$this-&gt;makeAdapterRequest($this-&gt;euroRequest).&quot;&lt;br /&gt;&quot;; echo &quot;dollar:&quot;.$this-&gt;makeDollarRequest($this-&gt;dollarRequest); &#125; public function makeAdapterRequest(ITarget $req) &#123; return $req-&gt;requestCalc(40,50); &#125; public function makeDollarRequest(DollarCalc $req) &#123; return $req-&gt;requestCalc(40,50); &#125;&#125;$worker = new Client(); 案例二 个人运用于自动化活动专题的接口设计抽奖例子（代码只显示对应的设计逻辑部分） 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596&lt;?php/** * 适配器模式 - 抽奖接口 * comment 当后台规则不满足自动化，可以添加对应的适配器，增加代码的复用 * author AT */namespace controller;// 每个月份对应的适配器 06年3月 = SixMarchuse \\Adapter\\SixMarch\\LotteryAdapter;/** * 抽奖接口 入口文件 */final class Lottery extends WebController&#123; // 活动的配置信息 存放后台配置的活动信息 private $hd_info; public function __construct() &#123; // 加载配置信息 $this-&gt;hd_info = &apos;&apos;; &#125; public function _lottery() &#123; // 实例 $lottery = new LotteryAdapter($hd_info); // 取得抽奖结果 $rs = $lottery-&gt;_getLotteryResult(); return $rs; &#125;&#125;namespace controller;use \\bbts\\App as BaseApp;/** * */class LotteryAdapter extends AutoLottery implements ILottery&#123; public function __construct($hd_info) &#123; // 后台配置是否需要使用适配器 if($hd_info[&apos;use_adapter&apos;] === true) &#123; $adapter_name = $hd_info[&apos;adapter_name&apos;]; // $adapter_name = &apos;adapter_name&apos;; test $this-&gt;$adapter_name(); &#125; &#125; /** * adapter_name 该活动对应的适配器 */ private function adapter_name() &#123; // 假设不符合自动化的需求条件是必须进入游戏后5分才可抽奖，增加适配器的该内容即可，从而不用重写整个抽奖活动 $game_info = App::$app-&gt;model()-&gt;checkEnterGameInfo(); if(strtotime($info[&apos;TIME&apos;]) - time() &lt; 300) &#123; $this-&gt;adapter_status = false; $this-&gt;adapter_code = -51; &#125; &#125;&#125;namespace controller;use \\bbts\\App as BaseApp;/** * 自动化抽奖接口的基类 */class AutoLottery &#123; // 单独开发条件的状态 public $adapter_status = true; public $adapter_code = 0; public function _getLotteryResult()&#123; // 最后判断适配器的状态 if(!$this-&gt;adapter_status) &#123; App::jetJsonpOutput($this-&gt;adapter_return_code); &#125; // 业务逻辑判断 // 通过则将数据入库 $rs_status = App::$app-&gt;model()-&gt;insert($rs); // 返回结果 return $rs; &#125;&#125;?&gt;","tags":[{"name":"php","slug":"php","permalink":"http://yoursite.com/tags/php/"},{"name":"设计模式","slug":"设计模式","permalink":"http://yoursite.com/tags/设计模式/"}]},{"title":"Redis-运用场景与介绍","date":"2016-04-27T13:38:58.000Z","path":"2016/04/27/Redis-运用场景与介绍/","text":"声明：该文章整理于公司redis培训的ppt redis 数据结构 string(字符串) list(双向链表) set(无序集合) zset(有序集合) hash(hash表) HyperLogLog string(字符串) 命令与运用场景 除了get、set、incr、decr mget等操作外，Redis还提供了下面一些操作： 获取字符串长度 strlen 往字符串append内容的末尾 设置和获取字符串的某一段内容 GETRANGE 设置及获取字符串的某一位（bit） 批量设置一系列字符串的内容 GETSET 可以和 INCR 组合使用，实现一个有原子性(atomic)复位操作的计数器(counter)。 运用场景防并发 12345678910/** * 加锁，防并发 * @param string $key * @param int $expire_time * @return Boolean */public function lock($key = &apos;&apos;, $expire_time = 15)&#123; return &apos;&apos;===$key ? false : self::initConnection()-&gt;set($key, 1, array(&quot;NX&quot;, &quot;EX&quot;=&gt;$expire_time));&#125; 限制ip (访问超过几次)。INCRBY命令来控制次数，通过原子递增保持计数。 list(双向链表) 命令与运用场景 lpush,rpush,lpop,rpop,lrange,BLPOP(阻塞版)等 应用场景： Redis list的应用场景非常多，也是Redis最重要的数据结构之一。 我们可以轻松地实现最新消息排行等功能。 Lists的另一个应用就是消息队列，可以利用Lists的PUSH操作，将任务存在Lists中，然后工作线程再用POP操作将任务取出进行执行 实现方式： Redis list的实现为一个双向链表，即可以支持反向查找和遍历，更方便操作，不过带来了部分额外的内存开销，Redis内部的很多实现，包括，发送缓冲队列等也都是用的这个数据结构 数据结构- 无序集合常用命令：sadd,srem,spop,sdiff ,smembers,sunion 等。 应用场景 set对外提供的功能与list类似是一个列表的功能，特殊之处在于set是可以自动排重的，当你需要存储一个列表数据，又不希望出现重复数据时，set是一个很好的选择，并且set提供了判断某个成员是否在一个set集合内的重要接口，这个也是list所不能提供的。 比如在微博应用中，每个人的好友存在一个集合（set）中，这样求两个人的共同好友的操作，可能就只需要用求交集命令即可。 Redis还为集合提供了求交集、并集、差集等操作，可以非常方便的实 实现方式： set 的内部实现是一个 value永远为null的HashMap，实际就是通过计算hash的方式来快速排重的，这也是set能提供判断一个成员是否在集合内的原因。 数据结构-有序集合常用命令： zadd,zrange,zrem,zcard等 使用场景： 以某个条件为权重，比如按顶的次数排序. ZREVRANGE命令可以用来按照得分来获取前100名的用户，ZRANK可以用来获取用户排名，非常直接而且操作容易。 Redis sorted set的使用场景与set类似，区别是set不是自动有序的，而sorted set可以通过用户额外提供一个优先级(score)的参数来为成员排序，并且是插入有序的，即自动排序。 比如:twitter 的public timeline可以以发表时间作为score来存储，这样获取时就是自动按时间排好序的。 实现方式： Redis sorted set的内部使用HashMap和跳跃表(SkipList)来保证数据的存储和有序，HashMap里放的是成员到score的映射，而跳跃表里存放的是所有的成员，排序依据是HashMap里存的score,使用跳跃表的结构可以获得比较高的查找效率，并且在实现上比较简单 数据结构-hash 类型常用命令： hget,hset,hgetall 等。 使用场景： 根据业务场景存放用户信息等 实现方式： 上面已经说到Redis Hash对应Value内部实际就是一个HashMap，实际这里会有2种不同实现，这个Hash的成员比较少时Redis为了节省内存会采用类似一维数组的方式来紧凑存储，而不会采用真正的HashMap结构，对应的value redisObject的encoding为zipmap,当成员数量增大时会自动转成真正的HashMap,此时encoding为ht 数据结构-HyperLogLog Redis HyperLogLog 是用来做基数统计的 算 法 ，HyperLogLog 的优点是，在输入元素的数量或者体积非常非常大时，计算基数所需的空间总是固定 的、并且是很小的。 在 Redis 里面，每个 HyperLogLog 键只需要花费 12 KB 内存，就可以计算接近 2^64 个不同元素的基 数。这和计算基数时，元素越多耗费内存就越多的集合形成鲜明对比。 但是，因为 HyperLogLog 只会根据输入元素来计算基数，而不会储存输入元素本身，所以 HyperLogLog 不能像集合那样，返回输入的各个元素。 注意事项：HyperLogLog是一种近似去重的算法，对于精度要求较高的业务场景，不能使用 命令总结对value 操作的命令 exists(key)：确认一个key是否存在 del(key)：删除一个key type(key)：返回值的类型 keys(pattern)：返回满足给定pattern的所有key randomkey：随机返回key空间的一个key rename(oldname, newname)：将key由oldname重命名为newname，若newname存在则删除newname表示的key dbsize：返回当前数据库中key的数目 expire：设定一个key的活动时间（s） ttl：获得一个key的活动时间 select(index)：按索引查询 move(key, dbindex)：将当前数据库中的key转移到有dbindex索引的数据库 flushdb：删除当前选择数据库中的所有key flushall：删除所有数据库中的所有key 对String 操作的命令 set(key, value)：给数据库中名称为key的string赋予值value get(key)：返回数据库中名称为key的string的value getset(key, value)：给名称为key的string赋予上一次的value mget(key1, key2,…, key N)：返回库中多个string（它们的名称为key1，key2…）的value setnx(key, value)：如果不存在名称为key的string，则向库中添加string，名称为key，值为value setex(key, time, value)：向库中添加string（名称为key，值为value）同时，设定过期时间time mset(key1, value1, key2, value2,…key N, value N)：同时给多个string赋值，名称为key i的string赋值value i msetnx(key1, value1, key2, value2,…key N, value N)：如果所有名称为key i的string都不存在，则向库中添加string，名称key i赋值为value i incr(key)：名称为key的string增1操作 incrby(key, integer)：名称为key的string增加integer decr(key)：名称为key的string减1操作 decrby(key, integer)：名称为key的string减少integer append(key, value)：名称为key的string的值附加value substr(key, start, end)：返回名称为key的string的value的子串 对List 操作的命令 rpush(key, value)：在名称为key的list尾添加一个值为value的元素 lpush(key, value)：在名称为key的list头添加一个值为value的 元素 llen(key)：返回名称为key的list的长度 lrange(key, start, end)：返回名称为key的list中start至end之间的元素（下标从0开始，下同） ltrim(key, start, end)：截取名称为key的list，保留start至end之间的元素 lindex(key, index)：返回名称为key的list中index位置的元素 lset(key, index, value)：给名称为key的list中index位置的元素赋值为value lrem(key, count, value)：删除count个名称为key的list中值为value的元素。count为0，删除所有值为value的元素，count&gt;0从头至尾删除count个值为value的元素，count&lt;0从尾到头删除|count|个值为value的元素。 lpop(key)：返回并删除名称为key的list中的首元素 rpop(key)：返回并删除名称为key的list中的尾元素 blpop(key1, key2,… key N, timeout)：lpop命令的block版本。即当timeout为0时，若遇到名称为key i的list不存在或该list为空，则命令结束。如果timeout&gt;0，则遇到上述情况时，等待timeout秒，如果问题没有解决，则对key i+1开始的list执行pop操作。 brpop(key1, key2,… key N, timeout)：rpop的block版本。参考上一命令。 rpoplpush(srckey, dstkey)：返回并删除名称为srckey的list的尾元素，并将该元素添加到名称为dstkey的list的头部 对Set 操作的命令 sadd(key, member)：向名称为key的set中添加元素member srem(key, member) ：删除名称为key的set中的元素member spop(key) ：随机返回并删除名称为key的set中一个元素 smove(srckey, dstkey, member) ：将member元素从名称为srckey的集合移到名称为dstkey的集合 scard(key) ：返回名称为key的set的基数 sismember(key, member) ：测试member是否是名称为key的set的元素 sinter(key1, key2,…key N) ：求交集 sinterstore(dstkey, key1, key2,…key N) ：求交集并将交集保存到dstkey的集合 sunion(key1, key2,…key N) ：求并集 sunionstore(dstkey, key1, key2,…key N) ：求并集并将并集保存到dstkey的集合 sdiff(key1, key2,…key N) ：求差集 sdiffstore(dstkey, key1, key2,…key N) ：求差集并将差集保存到dstkey的集合 smembers(key) ：返回名称为key的set的所有元素 srandmember(key) ：随机返回名称为key的set的一个元素 对zset （sorted set ）操作的命令 zadd(key, score, member)：向名称为key的zset中添加元素member，score用于排序。如果该元素已经存在，则根据score更新该元素的顺序。 zrem(key, member) ：删除名称为key的zset中的元素member zincrby(key, increment, member) ：如果在名称为key的zset中已经存在元素member，则该元素的score增加increment；否则向集合中添加该元素，其score的值为increment zrank(key, member) ：返回名称为key的zset（元素已按score从小到大排序）中member元素的rank（即index，从0开始），若没有member元素，返回“nil” zrevrank(key, member) ：返回名称为key的zset（元素已按score从大到小排序）中member元素的rank（即index，从0开始），若没有member元素，返回“nil” zrange(key, start, end)：返回名称为key的zset（元素已按score从小到大排序）中的index从start到end的所有元素 zrevrange(key, start, end)：返回名称为key的zset（元素已按score从大到小排序）中的index从start到end的所有元素 zrangebyscore(key, min, max)：返回名称为key的zset中score &gt;= min且score&lt;= max的所有元素 zcard(key)：返回名称为key的zset的基数 zscore(key, element)：返回名称为key的zset中元素element的score zremrangebyrank(key, min, max)：删除名称为key的zset中rank &gt;= min且rank &lt;= max的所有元素 zremrangebyscore(key, min, max) ：删除名称为key的zset中score &gt;= min且score &lt;= max的所有元素 zunionstore / zinterstore(dstkeyN, key1,…,keyN,WEIGHTS w1,…wN, AGGREGATE SUM|MIN|MAX)：对N个zset求并集和交集，并将最后的集合保存在dstkeyN中。对于集合中每一个元素的score，在进行AGGREGATE运算前，都要乘以对于的WEIGHT参数。如果没有提供WEIGHT，默认为1。默认的AGGREGATE是SUM，即结果集合中元素的score是所有集合对应元素进行SUM运算的值，而MIN和MAX是指，结果集合中元素的score是所有集合对应元素中最小值和最大值。 对Hash 操作的命令 hset(key, field, value)：向名称为key的hash中添加元素field&lt;—&gt;value hget(key, field)：返回名称为key的hash中field对应的value hmget(key, field1, …,field N)：返回名称为key的hash中field i对应的value hmset(key, field1, value1,…,field N, value N)：向名称为key的hash中添加元素field i&lt;—&gt;value i hincrby(key, field, integer)：将名称为key的hash中field的value增加integer hexists(key, field)：名称为key的hash中是否存在键为field的域 hdel(key, field)：删除名称为key的hash中键为field的域 hlen(key)：返回名称为key的hash中元素个数 hkeys(key)：返回名称为key的hash中所有键 hvals(key)：返回名称为key的hash中所有键对应的value hgetall(key)：返回名称为key的hash中所有的键（field）及其对应的value 对HyperLogLog 操作的命令 pfadd (key, value…)，向名称为key的hyploglog结构中增加value元素，返回boolean，true为已存在，false为不存在。注意：不能使用返回结果做累加统计元素数量 pfcount (key)，返回名称为key的hyploglog结构中元素的数量 pfmerge (key…) 合并多个hyploglog php 与redis predis扩展 phpredis包 对比： predis非侵入时，性能更好 phpredis，php编写，效率低于predis，无序安装扩展，支持composer 如何选择？更多的是个人习惯和团队规范 应用场景- 队列 使用redis链表，lpush/rpush和rpop/lpop操作链表实现队列进出 最佳实践：启用AOF持久化，批量入队列，批量取队列 场景： 分布式进程通信、配置分发 示例：https://github.com/huyanping/RedisStudy 问题：在大多队列的应用场景中，生产者的速度往往都会大于消费者的速度，如果保证队列不堆积？ 应用场景- 缓存 使用字典结构，通过set/get，hset/hget操作缓存数据 最佳实践：启用maxmemory限制，启用lru机制，设置expire，关闭AOF，考虑关闭dump 场景： 数据库缓存-减少响应时间 爬虫页面结果缓存-节省IO资源 计算结果缓存-节省CPU资源 应用场景- 归并计算 使用string类型，进行increment计数操作，减轻CPU或IO负载 最佳实践：启用AOF，关闭dump，批量操作 场景: 广告日志实时处理中心 应用场景- 去重 使用HyperLogLog进行IP去重 最佳实践：启用dump，关闭AOF，批量操作，巧用dabase场景： 广告实时处理中心唯一IP统计 redis-lua Lua 脚本功能是 Reids 2.6 版本的最大亮点， 通过内嵌对 Lua 环境的支持， Redis 解决了长久以来不能高效地处理 CAS （check-and-set）命令的缺点， 并且可以通过组合使用多个命令， 轻松实现以前很难实现或者不能高效实现的模式。 优点：原子性，更小的请求包 应用场景：事务实现，批量处理 命令： EVAL script numkeys key [key …] arg [arg …] script： 参数是一段 Lua 5.1 脚本程序。脚本不必(也不应该)定义为一个 Lua 函数。 numkeys： 用于指定键名参数的个数。 key [key …]： 从 EVAL 的第三个参数开始算起，表示在脚本中所用到的那些 Redis 键(key)，这些键名参数可以在 Lua 中通过全局变量 KEYS 数组，用 1 为基址的形式访问( KEYS[1] ，KEYS[2] ，以此类推)。 arg [arg …]： 附加参数，在 Lua 中通过全局变量 ARGV 数组访问，访问的形式和 KEYS 变量类似( ARGV[1] 、 ARGV[2] ，诸如此类)。 EVALSHA sha1 numkeys key [key …] arg [arg …] script： 参数是一段 Lua 5.1 脚本程序。脚本不必(也不应该)定义为一个 Lua 函数。 numkeys： 用于指定键名参数的个数。 key [key …]： 从 EVAL 的第三个参数开始算起，表示在脚本中所用到的那些 Redis 键(key)，这些键名参数可以在 Lua 中通过全局变量 KEYS数组，用 1 为基址的形式访问( KEYS[1] ， KEYS[2] ，以此类推)。 arg [arg …]： 附加参数，在 Lua 中通过全局变量 ARGV 数组访问，访问的形式和 KEYS 变量类似( ARGV[1] 、 ARGV[2] ，诸如此类)。 SCRIPT LOAD “return ‘hello moto’” EVALSHA “232fd51614574cf0867b83d384a5e898cfd24e5a” 0 故障-dump 故障 故障描述：redis使用dump持久化，未设置最大内存限制，dump时内存瞬时增加，大量使用swap分区，造成机器假死宕机 原因：redis使用dump持久化时，使用fork，子进程持有父进程内存的映像，在数据频繁更改的情况下，内存使用量会翻倍，内存不够的情况下，操作系统会使用swap分区。 经验：系统剩余内存不足redis占用内存2/3时，就会比较危险了 解决方案：设置maxmemroy，考虑启用lru，考虑关闭dump 故障-maxmemory 故障描述：设置了maxmemory，内存用完，客户端无法写入 解决方案：监控，根据业务场景控制内存使用；引入分布式redis集群方案 安全-redis 访问漏洞现象：服务器.ssh/authorized_keys文件被篡改，黑客最高可获得root权限，服务器被种木马原理：利用 Redis 自身的提供的 config 命令，可以进行写文件操作，攻击者可以成功将自己的公钥写入目标服务器的 /root/.ssh 文件夹的authotrized_keys 文件中，进而可以直接使用对应的私钥登录目标服务器。危害：数以万计的服务器被黑如何避免：防火墙，密码访问","tags":[{"name":"笔记","slug":"笔记","permalink":"http://yoursite.com/tags/笔记/"},{"name":"Redis","slug":"Redis","permalink":"http://yoursite.com/tags/Redis/"},{"name":"nosql","slug":"nosql","permalink":"http://yoursite.com/tags/nosql/"}]},{"title":"状态设计模式","date":"2016-04-12T14:59:32.000Z","path":"2016/04/12/状态设计模式/","text":"什么时候适用状态设计模式 有大量的判断状态的条件 状态模式的作用就是允许对象在状态改变时改变其行为，所以根据业务需求进行分析。 最基本的场景例子(比起全部判断语句的做法，这不是更好么) 开灯关灯 扩展 开灯-&gt;加亮-&gt;再加亮-&gt;关灯 九宫格的数字移动游戏 优点 它将与特定状态相关的行为局部化，并且将不同状态的行为分割开来: 代码清晰可见，扩展性好 缺点 状态模式的使用必然会增加系统类和对象的个数。 只做开灯关灯例子说明 学习于php 设计模式（强烈推荐这本书）123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137&lt;?php/** * content.class.php */class content &#123; private $onState; private $offState; private $currentState; public function __construct() &#123; $this-&gt;onState = new OnState($this); $this-&gt;offState = new offState($this); $this-&gt;currentState = $this-&gt;offState; &#125; /** * [trueOnLight 开灯] * @return [type] [description] */ public function trueOnLight() &#123; return $this-&gt;currentState-&gt;onLight(); &#125; /** * [trueOffLight 关灯] */ public function trueOffLight() &#123; return $this-&gt;currentState-&gt;offLight(); &#125; /** * [getState 取得关灯的实例] */ public function getOffState() &#123; return $this-&gt;offState; &#125; /** * [getOnState 取得开灯实例] * @return [type] [description] */ public function getOnState() &#123; return $this-&gt;onState; &#125; /** * [setState 设置当前的实例] * @param Istate $state [description] */ public function setState(Istate $state) &#123; $this-&gt;currentState = $state; &#125;&#125;/** * 接口 IState.php */interface IState &#123; function onLight(); function offLight();&#125;/** * 开灯状态 OnState.class.php */class OnState implements IState &#123; private $content; public function __construct(Content $content) &#123; $this-&gt;content = $content; &#125; /** * [onLight 开灯行为方法] */ public function onLight() &#123; return '已经开灯了&lt;br /&gt;'; &#125; /** * [offLight 关灯行为方法] */ public function offLight() &#123; $this-&gt;content-&gt;setState($this-&gt;content-&gt;getOffState()); return '关灯了&lt;br /&gt;'; &#125;&#125;/** * 关灯状态 OffState.class.php */class OffState implements IState &#123; private $content; public function __construct(Content $content) &#123; $this-&gt;content = $content; &#125; /** * [onLight 开灯行为方法] */ public function onLight() &#123; $this-&gt;content-&gt;setState($this-&gt;content-&gt;getOnState()); return '开灯了&lt;br /&gt;'; &#125; /** * [offLight 关灯行为方法] */ public function offLight() &#123; return '已经关灯了&lt;br /&gt;'; &#125;&#125;/** * 用户调用用例 */class client &#123; private $content; public function __construct() &#123; $this-&gt;content = new content(); echo $this-&gt;content-&gt;trueOnLight(); echo $this-&gt;content-&gt;trueOnLight(); echo $this-&gt;content-&gt;trueOffLight(); echo $this-&gt;content-&gt;trueOffLight();exit; &#125;&#125;$client = new client();?&gt;/** * 实例化一个Context 实例之后，初始请求是打开灯，因为灯默认是关的 ，请求显示的结果如下 * 开灯了 * 已经开灯了 * 关灯了 * 已经关灯了 */ 每一个行动中，我们必须把目光放到我们的过去、现在和将来的行动之外，还要超越这些行为影响到的其他人，而看到所有这一切之间的关系，这样一来，我们就会非常的谨慎","tags":[{"name":"php","slug":"php","permalink":"http://yoursite.com/tags/php/"},{"name":"设计模式","slug":"设计模式","permalink":"http://yoursite.com/tags/设计模式/"}]},{"title":"单例模式","date":"2016-04-11T12:04:54.000Z","path":"2016/04/11/单例模式/","text":"单例模式的特点 只能有一个实例 必须自行创建这个实例 必须给其他对象提供这一实例 单例类 构造函数需要标记为private（访问控制：防止外部代码使用new操作符创建对象），单例类不能在其他类中实例化，只能被其自身实例化； 拥有一个保存类的实例的静态成员变量(非成静态员：所有没有加Static的成员都是非静态成员,当类被实例化之后,可以通过实例化的类名进行访问..非静态成员的生存期决定于该类的生存期..而静态成员则不存在生存期的概念,因为静态成员始终驻留在内容中..) 拥有一个访问这个实例的公共的静态方法（常用getInstance()方法进行实例化单例类，通过instanceof操作符可以检测到类是否已经被实例化） 为什么要使用PHP单例模式？ 虽然PHP每次执行完页面都是会从内存中清理掉所有的资源. 因而PHP中的单例实际每次运行都是需要重新实例化的，但PHP一个主要应用场合就是应用程序与数据库打交道的场景，在一个应用中会存在大量的数据库操作，针对数据库句柄连接数据库的行为，使用单例模式可以避免大量的new操作。因为每一次new操作都会消耗系统和内存的资源。 优点： 改进系统的设计 是对全局变量的一种改进 缺点： 难于调试 隐藏的依赖关系 无法用错误类型的数据覆写一个单例","tags":[{"name":"php","slug":"php","permalink":"http://yoursite.com/tags/php/"},{"name":"设计模式","slug":"设计模式","permalink":"http://yoursite.com/tags/设计模式/"}]},{"title":"秒杀活动的架构设计","date":"2016-03-09T09:04:18.000Z","path":"2016/03/09/秒杀活动的架构设计/","text":"业务的基本说明 运营评估最高的并发会达到 10W（根据推广的力度，以及以往的经验） 业务现有的服务器架构 反向代理 4台，前端机 8台， db 2台（主从），redis 2台（主从）以下是服务器架构图 动静分离html 等静态文件上CDN ，这方面压力不大后台程序动态接口，必须支持高并发，用户体验必须做好后端程序优化点（欢迎大家补充） 程序尽可能的减少加载的文件 程序减少不必要的网络请求 redis 队列来作 异步方式实现 123// 后台进程消费队列 个人使用brpoplpush方法 取出数据并用存入另外队列作数据备份$block_expire_time = 0; # 设置阻塞等待时间为永久$redis-&gt;brpoplpush($key, $backup_key, $block_expire_time); redis 缓存 前端点击按钮请求后变灰，防止用户重复点击 静态文件上CDN nginx的最大连接数设置为550，防止连接数过大时全部到php，导致php服务挂了 针对每个用户加并发锁（redis），防止高并发情况判断条件被绕过,程序执行完后解锁。 1$lock_status = $redis-&gt;set($lock_key, 1, array(&quot;NX&quot;, &quot;EX&quot;=&gt;$expire_time)); 高并发下奖品超发问题个人设计的方案：提前把每个奖品放入 redis队列，每个key一个奖品，队列的长度是奖品的数量，可以保证奖品不会超发放另外，假设使用悲观锁，在更新数据的时候加锁，其它的都为等待状态，不合适秒杀场景乐观锁 基本是采用带版本号更新，版本号匹配才能更新，其它的回滚，虽然保证的数据的安全不超发放，但是在高并发场景下，DB只有两台的时候，超过mysql 进程堆积肯定会的， 超过最大连接数是怎么办，一系列的问题需要解决，所以该方案不合适 程序压测结果分析服务器能抗的并发在平均响应时间300ms内，单台qps 750 左右（保持300ms是公司压测试的规范指标）10台机器（后面新增2台到 8+2）一秒钟能处理： 10 * 750/0.3 = 25000但是系统在高并发的状态下，响应时间有可能从300ms 变成500ms，所以在做评估，需要预留一定的空间那么问题来了，保守的并发只有1.5W,与10w 差距大，需要在执行方案上解决，公司不可无限的申请web机器。解决10W并发问题(资源有限的情况)方案在代理层做处理，根据权重挡掉90%的量，返回800（自定义），前端判断是否为800，是则提示火爆用户重试（对应的方案设置友好一些） 活动的序列图及说明 接口程序不连接查询mysql数据库 奖品的数据存放redis队列，每个奖品一个key，队列长度是奖品的数量 用户成功领取红包（或抢购）时的代码流程（不包括业务限制与防刷），从队列获取奖品成功，再入队列（此队列后台消费入库），返回给用户领取成功。在用户体验上有所提升，但如果后台队列堆积太多，未能消费完成，用户查看的红包时是没有对应记录的，所以针对自己的需求作对应的优化。 活动流程图（开爷画的）","tags":[{"name":"架构设计","slug":"架构设计","permalink":"http://yoursite.com/tags/架构设计/"}]},{"title":"用脚步丈量家乡 - 汕尾","date":"2016-02-22T10:00:11.000Z","path":"2016/02/22/用脚步丈量家乡-汕尾/","text":"汕尾或许汕尾这个城市鲜为人知，一般情况下说汕尾，对方都会复读一次是“汕头”来确认，但汕尾确实是以后可以养老的好地方，空气质量好，生活节奏慢. 不过大家都为了理想而各奔东西，每年回家乡的次数也有限，借着春节的假期，各种聚会的疯狂过后，去认真的体会一下家乡的自然与空气，这种熟悉且又有了陌生的感觉，让人心平气静。 沿着汕尾海边街，一路顶着海风飞（man）奔（pao）起来，想知道在海边跑步是什么感受的话，我来告诉你，就一个字，爽。 下面贴个跑步的小地图 海边街相比广州珠江边，这里更具有清新的气息，看着这条路上运动的人越来越多，个人感觉是汕尾人民对自我生活的一种提升吧。 跑步有一片蓝天，像玩家有着好的游戏体验一样，跑步真是一项最简单的运动","tags":[{"name":"生活","slug":"生活","permalink":"http://yoursite.com/tags/生活/"}]},{"title":"Mysql 查询今天、昨天、最近7天、最近30天的优化","date":"2016-01-10T15:48:47.000Z","path":"2016/01/10/Mysql 查询今天、昨天、最近7天、最近30天的优化/","text":"表结构1234567CREATE TABLE `student` ( `id` int(11) NOT NULL AUTO_INCREMENT, `createtime` int(11) NOT NULL DEFAULT &apos;0&apos;, `price` varchar(32) NOT NULL, PRIMARY KEY (`id`), KEY `createtime` (`createtime`) USING BTREE) ENGINE=InnoDB CHARSET=utf8; 查询分析 今天、昨天、最近7天、最近30天的收入总数1234567explain select sum(price) as number from table where to_days(date_format(FROM_UNIXTIME(`createtime`),&apos;%Y-%m-%d&apos;))=to_days(now()) UNION ALL SELECT sum(price) as number FROM table WHERE TO_DAYS( NOW( ) ) - TO_DAYS( date_format(FROM_UNIXTIME(`createtime`),&apos;%Y-%m-%d&apos;)) &lt;= 1 &amp;&amp; to_days(date_format(FROM_UNIXTIME(`createtime`),&apos;%Y-%m-%d&apos;))!=to_days(now()) UNION ALL SELECT sum(price) as number FROM table where DATE_SUB(CURDATE(), INTERVAL 7 DAY) &lt;= date(date_format(FROM_UNIXTIME(`createtime`),&apos;%Y-%m-%d&apos;)) UNION ALL SELECT sum(price) as number FROM table where DATE_SUB(CURDATE(), INTERVAL 30 DAY) &lt;= date(date_format(FROM_UNIXTIME(`createtime`),&apos;%Y-%m-%d&apos;)) 加了索引的情况下用不到索引 这里是图片 使用php程序时使用12345678910111213141516explain select sum(price) as number from student where to_days(date_format(FROM_UNIXTIME(`createtime`),&apos;%Y-%m-%d&apos;))=to_days(now()) UNION ALL SELECT sum(price) as number FROM student WHERE TO_DAYS( NOW( ) ) - TO_DAYS( date_format(FROM_UNIXTIME(`createtime`),&apos;%Y-%m-%d&apos;)) &lt;= 1 &amp;&amp; to_days(date_format(FROM_UNIXTIME(`createtime`),&apos;%Y-%m-%d&apos;))!=to_days(now()) UNION ALL SELECT sum(price) as number FROM student where DATE_SUB(CURDATE(), INTERVAL 7 DAY) &lt;= date(date_format(FROM_UNIXTIME(`createtime`),&apos;%Y-%m-%d&apos;)) UNION ALL SELECT sum(price) as number FROM student where DATE_SUB(CURDATE(), INTERVAL 30 DAY) &lt;= date(date_format(FROM_UNIXTIME(`createtime`),&apos;%Y-%m-%d&apos;))explain select sum(price) as number from student where createtime&gt;=&apos;1489161600&apos;UNION ALL SELECT sum(price) as number FROM student WHERE createtime&gt;=&apos;1489075200&apos; &amp;&amp; createtime&lt;=&apos;1489161600&apos;UNION ALL SELECT sum(price) as number FROM student where createtime&gt;=&apos;1488556800&apos; &amp;&amp; createtime&lt;=&apos;1489247999&apos;UNION ALL SELECT sum(price) as number FROM student where createtime&gt;=&apos;1486483200&apos; &amp;&amp; createtime&lt;=&apos;1489247999&apos; 优化方法后续补","tags":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/tags/mysql/"}]},{"title":"mysql 数据阻塞，进程数满，服务挂了","date":"2016-01-08T14:35:40.000Z","path":"2016/01/08/mysql-数据阻塞，进程数满/","text":"出现慢查询且并发高的情景下一个中型的活动，当时做的时候不够细心，出现了数据库崩溃进入数据库 1show full processlist state 显示 sending data ，意思是从物理磁盘获取数据的进程当时数据更新sql语句写得不好，结果集达到了3W多，update 的数据只update一条，并发一过来，导致结果集全部锁着，释放不了导致大量请求阻塞在，连接数过多，mysql 服务器挂了，导致业务全面奔溃，准备写故障报告 解决方法 从慢日志当中查询到对应的sql语句，进行优化后发布代码 服务重启，因为不影响活动后续的进行 总结 针对任何活动不可大意，对每条sql亲自过一遍，避免低级错误重复出现 Freeing items 的情况(网上了解到还有这种状态)如果影响的结果集过大，说明索引项不够优化，Freeing items 当磁盘的 i/o 压力过大，也可能出现 Freeing items执行时间较长的情况 Sorting for … 跟sending data 情况一样结果集过大，排序条件没有优化，需要在内存里面优化，甚至需要创建临时结构排序 Copy to tmp table 索引及现有结构无法涵盖查询条件，才会建立一个临时表来满足查询要求，产生巨大的恐怖的i/o压力。Waiting for net, reading from net, writing to net 案例:因外挂程序，内网数据库大量读取，内网使用的百兆交换迅速爆满，导致大量连接阻塞在waiting for net，数据库连接过多崩溃","tags":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/tags/mysql/"},{"name":"笔记","slug":"笔记","permalink":"http://yoursite.com/tags/笔记/"}]},{"title":"Mysql 字段类型","date":"2016-01-03T12:16:38.000Z","path":"2016/01/03/Mysql-字段类型/","text":"CHAR 类型是定长 删除末尾的空格，不会删除前面的空格 适合存储很短的字符串，或者所有值都接近同一个长度。例如: 适合存储MD5的密码串 定长的CHAR不容易产生碎片 对于非常短的列，CHAR比VARCHAR在存储更有效率。例如: CHAR(1) 来存储只有Y 和 N 的值，VARCHAR需要2个字节，CHAR只需要一个字节 VARCHAR 可变长的字符串 比定长类型CHAR更节省空间 需要使用额外的1 个或2个字符串来记录字符串的长度，小于255 只使用一个字节，大于使用2个 整数类型 TINYINT - 8 , SMALLINT - 16, MEDIUMINT - 24, INT - 32, BIGINT - 64 位的存储空间 -2的N-1次方到 2的N-1次方-12:可选 UNSIGNED属性 ，表示不允许负值 ，大致可以使正数上限提高一倍 实数类型 实数是带有小数部分的数字，也可以使用BECIMAL 格式 create table ta (a float,b decimal(6,5));6为小数点左边的位数，5为小数点右边的位数，当插入的小数点右边的位数大于5 后面的将被截掉，当插入小数点左边的位数大于6时，将取 999999 DECIMAL 是存储精确的小数，应该尽量只在小数进行精确计算时才使用，但数据量较大时，可以考虑使用BIGINT代替，要精确到万分之一的数据，可以把所有金额乘以一百万再存储进BIGINT里。 FLOAT 占用4个字节 DOUBLE占用8个字节 相比FLOAT有更高的精度与更大的范围 DATETIME 和 TIMESAMP 都可以存储相同的数据，时间和日期 TIMESAMP 只使用DATETIME一半的存储空间（4个字节与8个字节），并且根据时区变化，具有特殊的自动更新能力，但TIMESTAMP允许的时间范围小得多 DATETIME 范围 1000-01-01 00:00:00 ~ 9999-12-31 23:59:59 TIMESAMP 范围 1970-01-01 08:00:01到2038-01-19 11:14:07 TIMESTAMP类型在默认情况下，insert、update 数据时，TIMESTAMP列会自动以当前时间（CURRENT_TIMESTAMP）填充/更新 使用INT存时间戳在业务上不方便处理的情况下，不建议使用 BLOB与TEXT 类型 BLOB 和TEXT类型都是为了存储很大的数据而设计的，分别采用二进制和字符方式存储 二进制类型有TINYBLOB,SMALLBLOB,BLOB,MEDIUMBLOB,LONGBLOB，字符类型是 TINYTEXT,SMALLTEXT,TEXT,MEDIUMTEXT,LONGTEXT，ENUM枚举与FIELD指定排序顺序 选择优化的数据类型 更小的数据类型通常更好,它们占用更小的磁盘，内存和CPU缓存，处理时需要的CPU周期更少 简单就好,整型比字符操作代价更低，因为字符集和校对规则使字符比较整型比较更复杂 尽量避免NULL 查询中包含可为NULL对MYSQL来说更难优化，因为可为NULL的列使得索引、索引统计和值 比较都较为复杂 可为NULL 的列使使用更多的存储空间，MYSQL里也需要特殊处理，当可为NULL被索引时,每个索引记录需要额外的字节 调优时，把可为NULL调为NOT NULL带来的性能提升比较小，除非确定此问题导致问题 使用VARCHAR(5) 与 VARCHAR(200)存储的区别 存储HELLO的空间开销是一样的，但是更长的列会消耗更多的内存，因为MYSQL通常会分配固定大小内存块来保存内部值 尤其是使用内存临时表时表进行排序或操作时会更糟糕","tags":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/tags/mysql/"},{"name":"笔记","slug":"笔记","permalink":"http://yoursite.com/tags/笔记/"}]},{"title":"Mysql 覆盖索引","date":"2016-01-02T02:53:13.000Z","path":"2016/01/02/Mysql-覆盖索引/","text":"概述 覆盖索引能够极大地提高性能。 考虑一下如果查询只需要扫描索引而无须回表，会带来多少好处 索引的条目通常远小于数据行大小，所以如果只需要读取索引，那极大地减少数据访问量，所以更内容全部放在内存中 索引是按照列值顺序存储的（至少单个页内是这样的） 一些存储引擎如MyISAM 的内存只缓存索引。 由于innodb 的聚簇索引，覆盖索引 对Innodb表特别有用。 Innodb的二级索引在叶子节点中保存了行的主键值，所以如果二级主键能够覆盖查询，则可以避免对主键索引的二次查询 mysql 只能用b-tree索引来做覆盖索引 当发起一个被索引覆盖的查询时，在 EXPLAIN 的extra列可以看到 “Using index”的信息 例子 explain select * from prodcuts where actor = &quot;yeyute&quot; and title like &apos; %aplollo%&apos;; 没有任务索引能够覆盖这个查询，因为查询从表中选择了所有的列， 不过 where 条件中的表是有索引可以覆盖的 mysql 不能在索引中执行like 操作 。 mysql5.5以为更早版本，只允许在索引中做简单操作（&gt; 和 &gt;= 和 != ）,这种情况，mysql 只能提取数据行的值而不是索引值来做比较 使用索引扫描来做排序 explain type列的值为“index” 如果索引不能覆盖查询所需的全部列，就得扫描查询所需的全部列 mysql 可以使用同一个索引既满足排序，又用于查找行 关联多表时，只有当order by 子句引用的字段全部为第一个表时，才能使用索引做排序 建立（sex,country），查询时不限制性别，可以在查询条件新增 sex in(‘m’,’f’) and country=’’ 来使用索引","tags":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/tags/mysql/"},{"name":"笔记","slug":"笔记","permalink":"http://yoursite.com/tags/笔记/"}]},{"title":"Mysql 聚簇索引(Clustered Index)","date":"2016-01-01T06:18:32.000Z","path":"2016/01/01/Mysql-聚簇索引/","text":"概述 每个表只能有一个聚簇索引，因为一个表中的记录只能以一种物理顺序存放，但是，一个表可以有不止一个非聚簇索引。例:你翻到新华字典的汉字“爬”那一页就是P开头的部分，这就是物理存储顺序（聚簇索引）；而不用你到目录，找到汉字“爬”所在的页码，然后根据页码找到这个字（非聚簇索引） 如果需要该索引,只要将索引指定为主键(primary key)就可以，根据主键创建聚簇索引 如果正在使用Innodb 表并且没有什么数据需要聚集，那么可以定义一个代理键作为主键，这种主键的数据应该和应用无关，最简单的方法是使用AUTO_INCREMENT 自增列。这样可以保证数据行是按顺序写入，对于根据主键做关联操作的性能也会更好。 顺序的主键会造成什么坏的结果？ 在高并发插入可能导致间隙锁竞争，可以考虑重新设计表，或者更改innodb_autoinc_lock_mode参数（innodb在语句1的实际插入操作执行前就预分配给该语句三个自增值，当有一个新的insert语句2要执行时，读取的AUTO_INCREMENT=4，这样虽然语句1可能还没有执行完，语句2就可直接执行无需等待语句2。） 什么时候用到聚簇索引以下将id设置为主键时，mysql 会根据主键创建聚簇索引,例：如果没设置主键，自增，where id=’1000’，是扫描全表123456CREATE TABLE `test_user` ( `id` int(11) NOT NULL AUTO_INCREMENT, `user_name` VARCHAR(32) NOT NULL DEFAULT &apos;&apos;, `password` CHAR(32) NOT NULL DEFAULT &apos;&apos;, PRIMARY KEY (`id`)) ENGINE=InnoDB CHARSET=utf8; 设置id为主键，自增，以下是对应的分析数据 1EXPLAIN select * from test_user where id=&apos;16000000&apos; ; 字段 值 说明 select_type simple 简单的 select 查询,不使用 union 及子查询 table test_user 表名 partitions null 列代表给定表所使用的分区 type const 是说明只有一条匹配值， possible_keys PRIMARY 指出 MySQL 能在该表中使用哪些索引有助于 查询。如果为空,说明没有可用的索引 key PRIMARY MySQL 实际从 possible_key 选择使用的索引 key_len 4 使用的索引的长度。在不损失精确性的情况 下,长度越短越好 ref const where 条件筛选后表上至多有一条元组匹配时 rows 1 MYSQL 认为必须检查的用来返回请求数据的行数 filtered 100 列给出了一个百分比的值，这个百分比值和rows列的值一起使用，可以估计出那些将要和QEP中的前一个表进行连接的行的数目。前一个表就是指id列的值比当前表的id小的表 主键设置为那个字段合适情况分析 选择聚簇索引应基于where子句和连接操作的类型。 在聚簇索引中不要包含经常修改的列，因为值修改后，数据行必须移动到新的位置。 大多数表都应该有聚簇索引或使用分区来降低对表尾页的竞争，在一个高事务的环境中，对最后一页的封锁严重影响系统的吞吐量 在聚簇索引下，数据在物理上按顺序排在数据页上，重复值也排在一起，因而在那些包含范围检查(between、&lt;、&lt;=、&amp; gt;、&gt;=)或使用group by或order by的查询时，一旦找到具有范围中第一个键值的行，具有后续索引值的行保证物理上毗连在一起而不必进一步搜索，避免了大范围扫描，可以大大提高查询速度。 在一个频繁发生插入操作的表上建立聚簇索引时，不要建在具有单调上升值的列(如IDENTITY)上，否则会经常引起封锁冲突。 用户名字段，可以设置为主键，但是不推荐1.用户名是比较规则字母数字序列，这可能导致性能上有所差别2.假如以用户名作为主键并与其他表关联，当删除用户时，再创建一个同名的用户，可能导致这些关联紊乱。而绝对唯一的ID则不会。3.有的系统可能会允许修改用户名，如果以用户名为主键，将带来很多麻烦。而如果以ID为主键进行关联，则没有此问题。 聚簇索引中的记录是如何存放 节点页只包含了索引列，叶子页包含了行的全部数据，就是既存储索引值,又在叶子中存储行的数据 Innodb是通过主键聚集数据，如果没有主键，Innodb会选择一个唯一的非空索引代替。如果没有这样的索引，会隐式定义一个主键来作为聚簇索引。 聚簇索引的每一个叶子节点都包含了主键值、事务ID、用于事务和MVCC的回滚指针以及所有的剩余列 优点 可以把相关的数据保存在一起。 例如电子邮件，可以根据用户ID来聚集数据，这样只需要从磁盘读取少数的数据页就能获取某个用户的全部邮件。如果没有使用聚簇索引，则每封邮件都可能导致一次磁盘的I/O. 数据访问更快。将索引和数据保存在同一个B-Tree中，因此从聚簇索引中获取数据通常比非聚簇索引查找更快 使用覆盖索引扫描的查询可以直接使用页节点中的主键值 缺点 聚簇数据最大限度地提高了I/O密集型应用的性能，但如果数据全部都放在内存中，则访问的顺序就没那么重要了，聚会簇索引也就没什么优势 更新索引列代价很大，因为innodb 强制将每个被更新的行移动到新的位置 插入的速度严重依赖于插入顺充，按照主键的顺序插入是加载数据到INNODB表中速度最快的方式，如果不是，那么加载完成后最好 使用optimize table命令重新排序 对于插入新行，或主键更新，导致需要移动行的时候，可能面临“页分裂”问题。 当行的主键值要求必须将这一行插入到某个已满的页中时，存储引擎会将该页分裂成两个页面来容纳该行，会导致表占用更大的磁盘空间 可能会导致全表扫描变慢，尤其是行比较稀疏 或者 页分裂 存储不连续的时候","tags":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/tags/mysql/"},{"name":"笔记","slug":"笔记","permalink":"http://yoursite.com/tags/笔记/"}]},{"title":"http 请求报文详解","date":"2015-09-02T16:51:24.000Z","path":"2015/09/03/http-请求信息详解/","text":"两类报文 请求报文 响应报文 报文分三部分对报文进行描述的起始行（start line）请求报文 GET /php.info HTTP/1.1 报文内容 说明 GET 请求的方法 /php.info 请求的地址 HTTP/1.1 请求版本 响应报文 HTTP/1.1 200 OK 报文内容 说明 HTTP/1.1 响应版本 200 OK 响应的状态码 内容 包含属性的首部（header）块请求报文 报文内容 说明 accept(接收) 指定客户端能够接收的内容类型 text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,/;q=0.8 Accept-Encoding gzip(数据格式 ), deflate(默认且目前仅使用deflate算法压缩data部分，此法用于压缩传输), sdch(即通过字典压缩算法对各个页面中相同的内容进行压缩，减少相同的内容的传输。如：一个网站中一般都是共同的头部和尾部，甚至一些侧边栏也是共同的。之前的方式每个页面打开的时候这些共同的信息都要重新加载，但使用SDCH压缩方式的话，那些共同的内容只用传输一次就可以了) Accept-Language zh-cn ,zh; q=0.8 接收语言Cache-Control: Cache-Control 值为private、no-cache、must-revalidate，那么打开新窗口访问时都会重新访问服务器。 而如果指定了max-age值，那么在此值内的时间里就不会重新访问服务器，例如： Cache-control: max-age=5(表示当访问此网页后的5秒 内再次访问不会去服务器) connection keep-alive 默认是长连接 其优点是、在资源包含多个元素是(比如web页面中的图片)将减少下载时间，当Connection为Keep-Alive时、表示在Keep-Alive时间内不会断开连接。而非KeepAlive模式时、请求之后都将会断开 host 域名或ip If-Modified-Since 使用If-Modified-Since标签，把上次服务器告诉它的文件最后修改时间返回到服务器端了，文件没有改动过，所以服务器返回的HTTP状态码是304，没有发送页面的内容 Upgrade-Insecure-Requests 值为1 则是告诉服务器，自己支持这种操作，也就是我能读懂你服务器发过来的上面这条信息，并且在以后发请求的时候不用http而用https User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/42.0.2311.135 Safari/537.36 表示请求的客户端浏览器详细信息 响应报文 报文内容 说明 Connection keep-alive* 默认是长连接 其优点是、在资源包含多个元素是(比如web页面中的图片)将减少下载时间，当Connection为Keep-Alive时、表示在Keep-Alive时间内不会断开连接。而非KeepAlive模式时、请求之后都将会断开 Content-Encoding 响应正文使用的数据压缩格式 Content-language 响应正文使用的语言 Content-Type 响应正文的类型（是图片还是二进制字符串） Date 服务器响应的时间 Last-Modified Sun, 26 Jun 2016 04:14:32 GMT* 最后修改的时间 Server nginx/1.6.2* http服务器的类型/版本 这个有时会造成有人专门利用特定版本网页服务器漏洞进行攻击，nginx可以在配置文件中增加或修改server_tokens off 来去除版本号 Link Accept-Encoding 响应头，明确告知缓存服务器按照 Accept-Encoding 字段的内容，分别缓存不同的版本 Set-Cookie AST_LANG=zh; expires=Mon, 26-Jun-2015 14:37:17 GMT; Max-Age=31536000; path=/; domain=.php.net* Transfer-Encoding chunked 分块编码 表示输出的内容长度不能确定，报文中的实体需要改为用一系列分块来传输，每个分块包含十六进制的长度值和数据，长度值独占一行，长度不包括它结尾的 CRLF(\\r\\n)，也不包括分块数据结尾的 CRLF。最后一个分块长度值必须为 0，对应的分块数据没有内容，表示实体结束 Vary 参考此文章 https://imququ.com/post/vary-header-in-http.html X-Frame-Options DENY：浏览器拒绝当前页面加载任何Frame页面，SAMEORIGIN：frame页面的地址只能为同源域名下的页面，ALLOW-FROM：origin为允许frame加载的页面地址 X-Powered-By PHP/5.2.1，可在php.ini中增加或修改 expose_php = Off关闭,使用了ThinkPHP会输出 ThinkPHP 2.0，可修改相关类文件关闭 Cache-Control max-age=600 表示当访问此网页后的600秒内 告诉浏览器再次访问不去访问服务器 Expires HTTP控制缓存的基本手段，这个属性告诉缓存器：相关副本在多长时间内是新鲜的。过了这个时间，缓存器就会向源服务器发送请求，检查文档是否被修 改。几乎所有的缓存服务器 Content-Length 实体长度 通常如果 Content-Length 比实际长度短，会造成内容被截断;如果比实体内容长，会造成 pending 可选的、包含数据的主体（body）就是http 要传输的内容","tags":[{"name":"http","slug":"http","permalink":"http://yoursite.com/tags/http/"}]},{"title":"http 代理","date":"2015-07-02T17:16:49.000Z","path":"2015/07/03/http-代理详解/","text":"web 代理(proxy)代理位于客户端和服务器之间，扮演“中间人”的角色，对web客户端来说是扮演服务器的角色，对服务器来说是扮演客户端的角色 代理与网关的对比代理连接的是两个或多个使用相同协议的应用程序网关扮演的是“协议转换器”的角色，即使客户端和服务器使用的是不同的协议，客户端也可以通过网关完成与服务器之间的事务处理，例：浏览器&lt;-&gt;web/e-mail 网关(pop) &lt;-&gt; e-mail服务器 ，网关将不同的协议连接起来 为什么使用代理，运用的场景 代理服务器可以看到并接触到所有流过的http流量，所以代理可以监视流量并对其进行修改应用的场景 集中式访问控制代理(对禁止的站点强行禁止访问) 集中式文档访问控制代理 安全防火墙(提高安全性，以便对流量进行详细的检查) web 缓存 反向代理，以制作于分布式网络 内容路由器（根据网络流量状态以及内容类型将请求导向特定的服务器） 转码器 例：可以在传输gif图片时，将其转换成jpeg图片，减少尺寸，也可以对图片进行压缩，同样可以对文本压缩 匿名者（主动从http报文中删除身份特性，例ip，from头部，referer(请求报头，告知服务器用户的来源页面)首部，cookie,uri的会话id） 反向代理与正向代理反射代理 - 保护和隐藏原始资源服务器 情景- 用户 c -&gt;代理 a -&gt;机器 b 正向代理 - 主体是 c，a是c的代理 反向代理 - 主体是 c，a是b的代理 代理服务器的部署的几种方式 出口代理 控制本地网络与大型因特网之间的流量，公司部分网站控制访问等 访问（入口）代理 用于处理客户的聚合请求，。ISP使用缓存代理来存储常用文档的副本来提高用户的下载速度 反向代理 网络交换代理 将具有足够能力的代理放在网络之间的因特网对等交换点上，通过缓存来减轻因特网节点的拥塞，并对流量进行监视 代理如何获取流量的 修改客户端 - 手动或自动修改浏览器代理配置，客户端的http请求直接发给代理 修改网络 - 在客户端不知道的情况下，拦截网络流量并将其导入代理，这种拦截称为拦截代理。例：连接使用公共wifi时，会有将所有的站点修改到本地的hosts,获取拦截的流量信息后再请求问点返回。","tags":[{"name":"笔记","slug":"笔记","permalink":"http://yoursite.com/tags/笔记/"},{"name":"http","slug":"http","permalink":"http://yoursite.com/tags/http/"}]},{"title":"CGI、FastCGI、PHP-CGI、PHP-FPM 关系简单分析","date":"2015-05-11T02:12:52.000Z","path":"2015/05/11/CGI、FastCGI、PHP-CGI、PHP-FPM-关系简单分析/","text":"CGI、FastCGI、PHP-CGI、PHP-FPM 关系简单总结 value Description CGI 抽象来说是通用的服务网关， 标准的CGI对每个请求都会解析php.ini文件，初始化执行环境 PHP-CGI php-cgi只是解释PHP脚本的程序而已 FastCGI 一种管理php-cgi的协议(抽象)，一套由操作系统管理的php-cgi管理程序(具体) ，是用来提高CGI程序性能的 PHP-FPM 实现fast-cgi协议的具体程序 例：mvc与tp框架的关系， mvc是一种设计模式，tp框架是实现mvc模式的具体程序。","tags":[{"name":"php","slug":"php","permalink":"http://yoursite.com/tags/php/"}]},{"title":"深入理解 Memcached","date":"2015-03-11T06:41:37.000Z","path":"2015/03/11/深入理解-Memcached/","text":"特性 单个item 最大的数据 1M 单进程最大的使用内存 2G ，需要更多内存时可开多个端口 memcached 是多线程，非阻塞io复用的网络模型，redis 是单线程 键长最大250字节 MEMCACHE_COMPRESSED为压缩选项，缩后数据一般为原数据大小的30%左右，节省了70%的传输性能消耗所得会大于文件压缩带来的性能损耗；存的数据的确有大于几百字节的，如果都是小于100字节的键值对，压缩可能反而带来膨胀， 常见的运用场景 memcached来保持session，实现session共享（session跨服务器的一种解决方案） 解释压缩 注：php 官网的memcache 扩展的最新几个版本，当value好像是大于20k时（具体数值待验证），会自动压缩，尝试过压缩后有乱码情况,尝试使用1。1版本的不会自动压缩的情况 1set($this-&gt;_key($key), $value, MEMCACHE_COMPRESSED, $ttl); MEMCACHE_COMPRESSED为压缩选项缩后数据一般为原数据大小的30%左右，节省了70%的传输性能消耗所得会大于文件压缩带来的性能损耗；存的数据的确有大于几百字节的，如果都是小于100字节的键值对，压缩可能反而带来膨胀，Memcached中都是按照固定大小分块存储的，最小也要88 B。所以对于过小数据带来的压缩膨胀并不是太大的问题； 内存管理机制（默认是使用Slab Allocatoion机制分配、管理内存） 将内存分割成各种尺寸的块(chunk),并把尺寸相同的块分成组(chunk的集合) page 是分配Slab的内存空间 默认是1M 根据Slab大小切分成chunk chunk:用户缓存记录的内存空间 Slab class：特定chunk的组 如何组织数据的呢？内存分配流程 内存单位 说明 slab 数据大小相似的为一类, 放在同一个slab中.(按照chunk分类) page 每个page分配1M大小, 该类slab下的chunk用完, 重新申请一个page; 分配一次的大小. 如果没有page, 每次分配初始化一个chunk太浪费资源. chunk 数据存放最小也是最大的单位, 一个key对应的数据不能跨chunk(默认最大为1M) 内存分配参数 说明 used_chunks 已分配给item的chunk数量, 只分配, 不一定使用（初始化） free_chunks 尚未分配的chunk数量, 由delete释放的chunk(get不到时也会释放) free_chunks_end 分配后还没有被使用过的chunk","tags":[{"name":"nosql","slug":"nosql","permalink":"http://yoursite.com/tags/nosql/"}]},{"title":"hexo 命令","date":"2015-03-10T02:06:47.000Z","path":"2015/03/10/hexo-命令/","text":"安装123456# 全局安装安装npm install hexo -g# 升级 npm update hexo -g # 初始化 hexo init 简写123456# 本地启动服务hexo s == hexo server # 生成静态文件hexo g = hexo generate # 部署,将代码上传到配置的服务器hexo d == hexo deploy 新建1234# 新建文章hexo new &quot;postName&quot;# 新建页面 hexo new page &quot;pageName&quot; 删除删除 ./source/_posts/里对应的md文件. ps:不能全部删除，会报错。然后对应执行 123hexo g == hexo generate#生成hexo s == hexo server #启动服务预览hexo d == hexo deploy#部署 hexo clean,直接把public下的所有文章和分类目录都删除了,tags,archices,categories也会重新布局,请小心操作 服务器123456789101112131415# Hexo 会监视文件变动并自动更新，您无须重启服务器。hexo server # 静态模式hexo server -s # 更改端口hexo server -p 5000 # 自定义 IPhexo server -i 192.168.1.1# 清除缓存 网页正常情况下可以忽略此条命令,public 文件夹内容将全部删除hexo clean # 生成静态网页hexo g # 开始部署hexo d 监视文件变动1234# 使用 Hexo 生成静态文件快速而且简单hexo generate# 监视文件变动hexo generate --watch","tags":[{"name":"笔记","slug":"笔记","permalink":"http://yoursite.com/tags/笔记/"}]}]